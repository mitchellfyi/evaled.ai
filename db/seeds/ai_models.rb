# frozen_string_literal: true

# Seed AI Models - Top models from major providers
ai_models = [
  # OpenAI Models
  {
    name: "GPT-4o",
    slug: "gpt-4o",
    provider: "OpenAI",
    family: "GPT-4",
    release_date: Date.new(2024, 5, 13),
    website_url: "https://openai.com",
    docs_url: "https://platform.openai.com/docs/models/gpt-4o",
    api_reference_url: "https://platform.openai.com/docs/api-reference",
    api_model_id: "gpt-4o",
    input_per_1m_tokens: 2.50,
    output_per_1m_tokens: 10.00,
    cached_input_per_1m_tokens: 1.25,
    batch_discount_percentage: 50,
    context_window: 128_000,
    max_output_tokens: 16_384,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["Multimodal (text + vision)", "Fast inference", "Strong reasoning"],
    best_for: ["General-purpose tasks", "Vision analysis", "Code generation"],
    limitations: ["No real-time data", "Knowledge cutoff"],
    status: "active"
  },
  {
    name: "GPT-4o mini",
    slug: "gpt-4o-mini",
    provider: "OpenAI",
    family: "GPT-4",
    release_date: Date.new(2024, 7, 18),
    website_url: "https://openai.com",
    docs_url: "https://platform.openai.com/docs/models/gpt-4o-mini",
    api_model_id: "gpt-4o-mini",
    input_per_1m_tokens: 0.15,
    output_per_1m_tokens: 0.60,
    cached_input_per_1m_tokens: 0.075,
    batch_discount_percentage: 50,
    context_window: 128_000,
    max_output_tokens: 16_384,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["Cost-effective", "Fast", "Good quality for price"],
    best_for: ["High-volume tasks", "Simple queries", "Cost-sensitive apps"],
    limitations: ["Less capable than full GPT-4o", "Smaller knowledge base"],
    status: "active"
  },
  {
    name: "o1",
    slug: "o1",
    provider: "OpenAI",
    family: "o1",
    release_date: Date.new(2024, 12, 17),
    website_url: "https://openai.com",
    docs_url: "https://platform.openai.com/docs/models/o1",
    api_model_id: "o1",
    input_per_1m_tokens: 15.00,
    output_per_1m_tokens: 60.00,
    cached_input_per_1m_tokens: 7.50,
    context_window: 200_000,
    max_output_tokens: 100_000,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Advanced reasoning", "Chain-of-thought", "Best for complex problems"],
    best_for: ["Math and science", "Complex coding", "Strategic analysis"],
    limitations: ["Higher cost", "Slower due to reasoning"],
    status: "active"
  },
  {
    name: "o3-mini",
    slug: "o3-mini",
    provider: "OpenAI",
    family: "o3",
    release_date: Date.new(2025, 1, 31),
    website_url: "https://openai.com",
    docs_url: "https://platform.openai.com/docs/models/o3-mini",
    api_model_id: "o3-mini",
    input_per_1m_tokens: 1.10,
    output_per_1m_tokens: 4.40,
    cached_input_per_1m_tokens: 0.55,
    context_window: 200_000,
    max_output_tokens: 100_000,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Fast reasoning", "Cost-effective reasoning", "Adjustable effort"],
    best_for: ["STEM tasks", "Coding", "Math"],
    limitations: ["No vision", "Less capable than full o1"],
    status: "active"
  },

  # Anthropic Models
  {
    name: "Claude 3.5 Sonnet",
    slug: "claude-3-5-sonnet",
    provider: "Anthropic",
    family: "Claude 3.5",
    release_date: Date.new(2024, 10, 22),
    website_url: "https://anthropic.com",
    docs_url: "https://docs.anthropic.com/en/docs/about-claude/models",
    api_reference_url: "https://docs.anthropic.com/en/api",
    api_model_id: "claude-3-5-sonnet-20241022",
    input_per_1m_tokens: 3.00,
    output_per_1m_tokens: 15.00,
    cached_input_per_1m_tokens: 1.50,
    context_window: 200_000,
    max_output_tokens: 8192,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Best for coding", "Strong analysis", "Computer use capability"],
    best_for: ["Complex coding tasks", "Long-form analysis", "Agentic workflows"],
    limitations: ["No fine-tuning", "8K max output"],
    status: "active"
  },
  {
    name: "Claude 3.5 Haiku",
    slug: "claude-3-5-haiku",
    provider: "Anthropic",
    family: "Claude 3.5",
    release_date: Date.new(2024, 10, 22),
    website_url: "https://anthropic.com",
    docs_url: "https://docs.anthropic.com/en/docs/about-claude/models",
    api_model_id: "claude-3-5-haiku-20241022",
    input_per_1m_tokens: 0.80,
    output_per_1m_tokens: 4.00,
    cached_input_per_1m_tokens: 0.08,
    context_window: 200_000,
    max_output_tokens: 8192,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Fast inference", "Cost-effective", "Good for simple tasks"],
    best_for: ["Simple Q&A", "Classification", "High-volume processing"],
    limitations: ["No vision", "Less capable than Sonnet"],
    status: "active"
  },
  {
    name: "Claude 3 Opus",
    slug: "claude-3-opus",
    provider: "Anthropic",
    family: "Claude 3",
    release_date: Date.new(2024, 3, 4),
    website_url: "https://anthropic.com",
    docs_url: "https://docs.anthropic.com/en/docs/about-claude/models",
    api_model_id: "claude-3-opus-20240229",
    input_per_1m_tokens: 15.00,
    output_per_1m_tokens: 75.00,
    cached_input_per_1m_tokens: 7.50,
    context_window: 200_000,
    max_output_tokens: 4096,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Highest capability in Claude 3", "Strong reasoning", "Creative writing"],
    best_for: ["Complex research", "Creative writing", "Detailed analysis"],
    limitations: ["Higher cost", "Slower than Sonnet", "4K max output"],
    status: "active"
  },

  # Google Models
  {
    name: "Gemini 2.0 Flash",
    slug: "gemini-2-0-flash",
    provider: "Google",
    family: "Gemini 2.0",
    release_date: Date.new(2025, 2, 5),
    website_url: "https://ai.google.dev",
    docs_url: "https://ai.google.dev/gemini-api/docs",
    api_reference_url: "https://ai.google.dev/api",
    api_model_id: "gemini-2.0-flash",
    input_per_1m_tokens: 0.10,
    output_per_1m_tokens: 0.40,
    context_window: 1_048_576,
    max_output_tokens: 8192,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    free_tier_description: "Free tier available",
    key_features: ["1M context window", "Multimodal", "Very cost-effective"],
    best_for: ["Long document analysis", "Multimodal tasks", "Cost-sensitive apps"],
    limitations: ["8K max output", "Newer model, less battle-tested"],
    status: "active"
  },
  {
    name: "Gemini 1.5 Pro",
    slug: "gemini-1-5-pro",
    provider: "Google",
    family: "Gemini 1.5",
    release_date: Date.new(2024, 5, 14),
    website_url: "https://ai.google.dev",
    docs_url: "https://ai.google.dev/gemini-api/docs",
    api_model_id: "gemini-1.5-pro",
    input_per_1m_tokens: 1.25,
    output_per_1m_tokens: 5.00,
    context_window: 2_097_152,
    max_output_tokens: 8192,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    free_tier_description: "Free tier available",
    key_features: ["2M context window", "Multimodal", "Fine-tuning support"],
    best_for: ["Very long documents", "Video understanding", "Complex analysis"],
    limitations: ["8K max output", "Rate limits on free tier"],
    status: "active"
  },
  {
    name: "Gemini 1.5 Flash",
    slug: "gemini-1-5-flash",
    provider: "Google",
    family: "Gemini 1.5",
    release_date: Date.new(2024, 5, 14),
    website_url: "https://ai.google.dev",
    docs_url: "https://ai.google.dev/gemini-api/docs",
    api_model_id: "gemini-1.5-flash",
    input_per_1m_tokens: 0.075,
    output_per_1m_tokens: 0.30,
    context_window: 1_048_576,
    max_output_tokens: 8192,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    free_tier_description: "Free tier available",
    key_features: ["1M context window", "Very fast", "Ultra cost-effective"],
    best_for: ["High-volume processing", "Simple tasks", "Budget apps"],
    limitations: ["Less capable than Pro", "8K max output"],
    status: "active"
  },

  # Meta Models
  {
    name: "Llama 3.3 70B",
    slug: "llama-3-3-70b",
    provider: "Meta",
    family: "Llama 3.3",
    release_date: Date.new(2024, 12, 6),
    website_url: "https://llama.meta.com",
    docs_url: "https://llama.meta.com/docs",
    github_url: "https://github.com/meta-llama/llama-models",
    api_model_id: "meta-llama/Llama-3.3-70B-Instruct",
    input_per_1m_tokens: 0.60,
    output_per_1m_tokens: 0.60,
    context_window: 128_000,
    max_output_tokens: 4096,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["Open source", "Self-hostable", "Strong multilingual"],
    best_for: ["Self-hosted deployments", "Custom fine-tuning", "Privacy-sensitive apps"],
    limitations: ["No vision", "Requires hosting infrastructure"],
    status: "active"
  },
  {
    name: "Llama 3.1 405B",
    slug: "llama-3-1-405b",
    provider: "Meta",
    family: "Llama 3.1",
    release_date: Date.new(2024, 7, 23),
    website_url: "https://llama.meta.com",
    docs_url: "https://llama.meta.com/docs",
    github_url: "https://github.com/meta-llama/llama-models",
    api_model_id: "meta-llama/Meta-Llama-3.1-405B-Instruct",
    input_per_1m_tokens: 3.00,
    output_per_1m_tokens: 3.00,
    context_window: 128_000,
    max_output_tokens: 4096,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["Largest open model", "Open source", "Near-frontier quality"],
    best_for: ["Research", "Complex tasks requiring open models", "Self-hosted"],
    limitations: ["Expensive to host", "No vision", "Requires significant compute"],
    status: "active"
  },
  {
    name: "Llama 3.2 11B Vision",
    slug: "llama-3-2-11b-vision",
    provider: "Meta",
    family: "Llama 3.2",
    release_date: Date.new(2024, 9, 25),
    website_url: "https://llama.meta.com",
    docs_url: "https://llama.meta.com/docs",
    github_url: "https://github.com/meta-llama/llama-models",
    api_model_id: "meta-llama/Llama-3.2-11B-Vision-Instruct",
    input_per_1m_tokens: 0.18,
    output_per_1m_tokens: 0.18,
    context_window: 128_000,
    max_output_tokens: 4096,
    supports_vision: true,
    supports_function_calling: false,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["Open source vision model", "Lightweight", "Self-hostable"],
    best_for: ["Edge deployments", "Vision tasks on budget", "Self-hosted multimodal"],
    limitations: ["Smaller model, less capable", "Limited function calling"],
    status: "active"
  },

  # Mistral Models
  {
    name: "Mistral Large",
    slug: "mistral-large",
    provider: "Mistral",
    family: "Mistral Large",
    release_date: Date.new(2024, 11, 18),
    website_url: "https://mistral.ai",
    docs_url: "https://docs.mistral.ai",
    api_reference_url: "https://docs.mistral.ai/api",
    api_model_id: "mistral-large-latest",
    input_per_1m_tokens: 2.00,
    output_per_1m_tokens: 6.00,
    context_window: 128_000,
    max_output_tokens: 8192,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Strong reasoning", "Multilingual", "Code generation"],
    best_for: ["Complex reasoning", "Multilingual tasks", "Code generation"],
    limitations: ["No vision", "Smaller ecosystem"],
    status: "active"
  },
  {
    name: "Mistral Small",
    slug: "mistral-small",
    provider: "Mistral",
    family: "Mistral Small",
    release_date: Date.new(2025, 1, 30),
    website_url: "https://mistral.ai",
    docs_url: "https://docs.mistral.ai",
    api_model_id: "mistral-small-latest",
    input_per_1m_tokens: 0.10,
    output_per_1m_tokens: 0.30,
    context_window: 32_000,
    max_output_tokens: 8192,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["Very cost-effective", "Fast", "Good for simple tasks"],
    best_for: ["Classification", "Simple generation", "High-volume"],
    limitations: ["Smaller context window", "No vision"],
    status: "active"
  },
  {
    name: "Codestral",
    slug: "codestral",
    provider: "Mistral",
    family: "Codestral",
    release_date: Date.new(2024, 5, 29),
    website_url: "https://mistral.ai",
    docs_url: "https://docs.mistral.ai",
    api_model_id: "codestral-latest",
    input_per_1m_tokens: 0.30,
    output_per_1m_tokens: 0.90,
    context_window: 32_000,
    max_output_tokens: 8192,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Optimized for code", "80+ programming languages", "Fill-in-the-middle"],
    best_for: ["Code generation", "Code completion", "Code review"],
    limitations: ["Specialized for code", "No vision", "32K context"],
    status: "active"
  },

  # Cohere Models
  {
    name: "Command R+",
    slug: "command-r-plus",
    provider: "Cohere",
    family: "Command R",
    release_date: Date.new(2024, 4, 4),
    website_url: "https://cohere.com",
    docs_url: "https://docs.cohere.com",
    api_reference_url: "https://docs.cohere.com/reference",
    api_model_id: "command-r-plus",
    input_per_1m_tokens: 2.50,
    output_per_1m_tokens: 10.00,
    context_window: 128_000,
    max_output_tokens: 4096,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: true,
    supports_embedding: false,
    key_features: ["RAG optimized", "Multilingual", "Enterprise focused"],
    best_for: ["RAG applications", "Enterprise search", "Multilingual tasks"],
    limitations: ["No vision", "Smaller community"],
    status: "active"
  },

  # xAI Models
  {
    name: "Grok 2",
    slug: "grok-2",
    provider: "xAI",
    family: "Grok",
    release_date: Date.new(2024, 12, 12),
    website_url: "https://x.ai",
    docs_url: "https://docs.x.ai",
    api_reference_url: "https://docs.x.ai/api",
    api_model_id: "grok-2-latest",
    input_per_1m_tokens: 2.00,
    output_per_1m_tokens: 10.00,
    context_window: 131_072,
    max_output_tokens: 8192,
    supports_vision: true,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Real-time data access", "Vision support", "Strong reasoning"],
    best_for: ["Real-time queries", "Current events", "Vision analysis"],
    limitations: ["Newer platform", "Smaller ecosystem"],
    status: "active"
  },

  # DeepSeek Models
  {
    name: "DeepSeek V3",
    slug: "deepseek-v3",
    provider: "DeepSeek",
    family: "DeepSeek V3",
    release_date: Date.new(2024, 12, 26),
    website_url: "https://deepseek.com",
    docs_url: "https://api-docs.deepseek.com",
    github_url: "https://github.com/deepseek-ai/DeepSeek-V3",
    api_model_id: "deepseek-chat",
    input_per_1m_tokens: 0.27,
    output_per_1m_tokens: 1.10,
    cached_input_per_1m_tokens: 0.07,
    context_window: 64_000,
    max_output_tokens: 8192,
    supports_vision: false,
    supports_function_calling: true,
    supports_json_mode: true,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Very cost-effective", "Open source", "Strong coding"],
    best_for: ["Budget-conscious apps", "Coding tasks", "General purpose"],
    limitations: ["No vision", "Smaller context than competitors"],
    status: "active"
  },
  {
    name: "DeepSeek R1",
    slug: "deepseek-r1",
    provider: "DeepSeek",
    family: "DeepSeek R1",
    release_date: Date.new(2025, 1, 20),
    website_url: "https://deepseek.com",
    docs_url: "https://api-docs.deepseek.com",
    github_url: "https://github.com/deepseek-ai/DeepSeek-R1",
    api_model_id: "deepseek-reasoner",
    input_per_1m_tokens: 0.55,
    output_per_1m_tokens: 2.19,
    cached_input_per_1m_tokens: 0.14,
    context_window: 64_000,
    max_output_tokens: 8192,
    supports_vision: false,
    supports_function_calling: false,
    supports_json_mode: false,
    supports_streaming: true,
    supports_fine_tuning: false,
    supports_embedding: false,
    key_features: ["Reasoning model", "Open source", "Chain-of-thought"],
    best_for: ["Math", "Logic puzzles", "Scientific reasoning"],
    limitations: ["No vision", "No function calling", "No JSON mode"],
    status: "active"
  }
]

ai_models.each do |attrs|
  AiModel.find_or_create_by!(slug: attrs[:slug]) do |model|
    model.assign_attributes(attrs.merge(last_updated_at: Time.current))
  end
end

puts "  Seeded #{ai_models.size} AI models"
